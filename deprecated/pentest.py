import cv2
import numpy as np
from ultralytics import YOLO
import cvzone
import numpy as np

def RGB(event, x, y, flags, param):
    if event == cv2.EVENT_MOUSEMOVE:
        point = [x, y]
        print(point)

cv2.namedWindow('RGB')
cv2.setMouseCallback('RGB', RGB)

# Load the YOLO11 model for people and a separate model for hands and pens
person_model = YOLO("../models/yolo11n.pt")
hand_pen_model = YOLO("../models/yolov8n.pt") # Using a more common model for hands/pens
person_names = person_model.model.names
hand_pen_names = hand_pen_model.model.names

# Open the video file (use video file or webcam, here using webcam)
rtsp_url = "rtsp://192.168.33.109:554/0/0/0"

cap = cv2.VideoCapture(rtsp_url)
count = 0
cy1 = 261
cy2 = 286
offset = 8
inp = {}
enter = []
exp = {}
exitp = []
counting_people = True
tracked_person_id = None

while True:
    ret, frame = cap.read()
    if not ret:
        break
    count += 1
    if count % 3 != 0:
        continue

    frame = cv2.resize(frame, (1020, 600))
    frame_height, frame_width, _ = frame.shape
    half_frame_area = (frame_height * frame_width) / 2

    if counting_people:
        # Run YOLO11 tracking for people
        person_results = person_model.track(frame, persist=True, classes=0)

        # Check if there are any people detected
        if person_results[0].boxes is not None and person_results[0].boxes.id is not None:
            person_boxes = person_results[0].boxes.xyxy.int().cpu().tolist()
            person_track_ids = person_results[0].boxes.id.int().cpu().tolist()
            person_confidences = person_results[0].boxes.conf.cpu().tolist()

            largest_person_area = 0
            largest_person_box = None
            largest_person_track_id = None

            for box, track_id, conf in zip(person_boxes, person_track_ids, person_confidences):
                x1, y1, x2, y2 = box
                area = (x2 - x1) * (y2 - y1)
                if area > largest_person_area:
                    largest_person_area = area
                    largest_person_box = box
                    largest_person_track_id = track_id

                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cvzone.putTextRect(frame, f'{track_id}', (x1, y2), 1, 1)
                cvzone.putTextRect(frame, f'{person_names[0]}', (x1, y1), 1, 1) # Assuming class 0 is 'person'

            if largest_person_box is not None and largest_person_area > half_frame_area:
                counting_people = False
                tracked_person_id = largest_person_track_id
                print(f"Person with ID {tracked_person_id} taking up more than half the screen. Now tracking hand and pen.")

    else:
        # Track the specific person's hand and check for a pen
        if tracked_person_id is not None:
            person_results = person_model.track(frame, persist=True, classes=0, ids=[tracked_person_id])
            if person_results[0].boxes:
                person_box = person_results[0].boxes.xyxy.int().cpu().tolist()[0]
                px1, py1, px2, py2 = person_box
                cv2.rectangle(frame, (px1, py1), (px2, py2), (255, 0, 0), 2) # Highlight the tracked person

                # Define a region of interest around the person (you might need to adjust this)
                roi = frame[py1:py2, px1:px2]
                if roi.shape[0] > 0 and roi.shape[1] > 0:
                    hand_pen_results = hand_pen_model.predict(roi)
                    for det in hand_pen_results:
                        if det.boxes is not None:
                            for *xyxy, conf, cls in reversed(det.boxes):
                                x_min, y_min, x_max, y_max = map(int, xyxy)
                                # Adjust coordinates to be within the main frame
                                rx1, ry1, rx2, ry2 = px1 + x_min, py1 + y_min, px1 + x_max, py1 + y_max
                                label = hand_pen_names[int(cls)]
                                cvzone.putTextRect(frame, f'{label} {conf:.2f}', (rx1, ry1 - 10), 1, 1)
                                cv2.rectangle(frame, (rx1, ry1), (rx2, ry2), (0, 255, 0), 2)
                                if label == 'pen':
                                    cv2.rectangle(frame, (rx1, ry1), (rx2, ry2), (0, 0, 255), 3) # Highlight pen in red

    # cv2.line(frame,(440,286),(1018,286),(0,0,255),2)
    # cv2.line(frame,(438,261),(1018,261),(255,0,255),2)

    cv2.imshow("RGB", frame)
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

# Release the video capture object and close the display window
cap.release()
cv2.destroyAllWindows()
